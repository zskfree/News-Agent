"""
ç”Ÿæˆç´¯ç§¯æ–°é—»æ±‡æ€»

è¯¥è„šæœ¬è·å–æ‰€æœ‰RSSè®¢é˜…æºçš„å†å²æ–°é—»ï¼Œå¹¶è¿½åŠ åˆ°ç´¯ç§¯çš„Markdownæ–‡æ¡£ä¸­ï¼Œ
åŒ…å«å»é‡åŠŸèƒ½ï¼Œé€‚åˆå®šæœŸæ‰§è¡Œæ›´æ–°ã€‚
"""

import sys
import os
from datetime import datetime

try:
    from src.rss_read import generate_historical_news_by_categories
    from src.load_rss_url import load_rss_sources
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿srcç›®å½•ä¸­åŒ…å«rss_read.pyå’Œload_rss_url.pyæ–‡ä»¶")
    sys.exit(1)

def main():
    """
    ä¸»å‡½æ•°ï¼šç”Ÿæˆç´¯ç§¯æ–°é—»æ±‡æ€»
    """
    print("=" * 60)
    print("ğŸ”„ ç´¯ç§¯æ–°é—»æ±‡æ€»ç”Ÿæˆå™¨")
    print("=" * 60)
    
    # é…ç½®å‚æ•° - ä½¿ç”¨è·¨å¹³å°è·¯å¾„
    RSS_CONFIG_FILE = os.path.join('RSS feed URL', 'rss_feed_url.json')
    output_dir = "cumulative_news"  # ç´¯ç§¯æ–°é—»è¾“å‡ºç›®å½•
    max_articles_per_source = 100000  # æ¯ä¸ªæºæœ€å¤šè·å–çš„æ–‡ç« æ•°é‡
    max_summary_reports = 10  # æœ€å¤šä¿ç•™çš„æ±‡æ€»æŠ¥å‘Šæ•°é‡
    
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"  - RSSé…ç½®æ–‡ä»¶: {RSS_CONFIG_FILE}")
    print(f"  - è¾“å‡ºç›®å½•: {output_dir}")
    print(f"  - æ¯æºæœ€å¤§æ–‡ç« æ•°: {max_articles_per_source}")
    print(f"  - æœ€å¤§æ±‡æ€»æŠ¥å‘Šæ•°: {max_summary_reports}")
    print()
    
    # æ£€æŸ¥RSSé…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(RSS_CONFIG_FILE):
        print(f"âŒ RSSé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {RSS_CONFIG_FILE}")
        
        # è°ƒè¯•ï¼šæ˜¾ç¤ºå½“å‰ç›®å½•ç»“æ„
        print("\nğŸ” è°ƒè¯•ä¿¡æ¯ - å½“å‰ç›®å½•ç»“æ„:")
        print(f"   å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
        print("   æ ¹ç›®å½•å†…å®¹:")
        for item in os.listdir('.'):
            if os.path.isdir(item):
                print(f"     ğŸ“ {item}/")
            else:
                print(f"     ğŸ“„ {item}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸ä¼¼çš„ç›®å½•
        similar_dirs = [d for d in os.listdir('.') if 'rss' in d.lower() or 'feed' in d.lower() or 'url' in d.lower()]
        if similar_dirs:
            print("   ç›¸å…³ç›®å½•:")
            for dir_name in similar_dirs:
                print(f"     ğŸ“ {dir_name}/")
                if os.path.isdir(dir_name):
                    try:
                        files = os.listdir(dir_name)
                        for file in files[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶
                            print(f"        ğŸ“„ {file}")
                        if len(files) > 5:
                            print(f"        ... è¿˜æœ‰ {len(files) - 5} ä¸ªæ–‡ä»¶")
                    except:
                        pass
        
        return False
    
    try:
        # åŠ è½½RSSæºé…ç½®
        print("ğŸ“š åŠ è½½RSSè®¢é˜…æºé…ç½®...")
        rss_sources = load_rss_sources(RSS_CONFIG_FILE)
        
        if not rss_sources:
            print("âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•RSSè®¢é˜…æºé…ç½®")
            return False
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(rss_sources)} ä¸ªRSSè®¢é˜…æº")
        
        # ç»Ÿè®¡åˆ†ç±»ä¿¡æ¯
        categories = {}
        for source in rss_sources:
            category = source.get('category', 'æœªåˆ†ç±»')
            categories[category] = categories.get(category, 0) + 1
        
        print(f"\nğŸ“‚ å‘ç° {len(categories)} ä¸ªåˆ†ç±»:")
        for category, count in categories.items():
            print(f"  - {category}: {count} ä¸ªè®¢é˜…æº")
        
        print("\n" + "-" * 60)
        
        # ç”Ÿæˆç´¯ç§¯æ–°é—»æ±‡æ€»
        print("ğŸ”„ å¼€å§‹è·å–å†å²æ–°é—»å¹¶æ›´æ–°ç´¯ç§¯æ–‡æ¡£...")
        results = generate_historical_news_by_categories(
            rss_sources=rss_sources,
            output_dir=output_dir,
            max_articles_per_source=max_articles_per_source,
            max_summary_reports=max_summary_reports
        )
        
        if not results:
            print("âŒ å¤„ç†å¤±è´¥")
            return False
        
        # è¾“å‡ºå¤„ç†ç»“æœç»Ÿè®¡
        print("\n" + "=" * 60)
        print("ğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡:")
        print("=" * 60)
        
        successful_categories = []
        failed_categories = []
        total_new_articles = 0
        total_duplicate_articles = 0
        
        for category, result in results.items():
            if result.get('success', False):
                successful_categories.append(category)
                new_count = result.get('new_count', 0)
                duplicate_count = result.get('duplicate_count', 0)
                total_new_articles += new_count
                total_duplicate_articles += duplicate_count
                
                print(f"âœ… {category}:")
                print(f"   ğŸ“„ æ–‡ä»¶: {os.path.basename(result['file_path'])}")
                print(f"   ğŸ†• æ–°å¢æ–‡ç« : {new_count}")
                print(f"   ğŸ”„ é‡å¤æ–‡ç« : {duplicate_count}")
                print(f"   ğŸ”— è®¢é˜…æºæ•°: {result.get('source_count', 0)}")
            else:
                failed_categories.append(category)
                error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
                print(f"âŒ {category}: {error_msg}")
        
        print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"  âœ… æˆåŠŸå¤„ç†: {len(successful_categories)}/{len(results)} ä¸ªåˆ†ç±»")
        print(f"  ğŸ†• æ–°å¢æ–‡ç« æ€»æ•°: {total_new_articles}")
        print(f"  ğŸ”„ é‡å¤æ–‡ç« æ€»æ•°: {total_duplicate_articles}")
        print(f"  ğŸ“ è¾“å‡ºç›®å½•: {os.path.abspath(output_dir)}")
        
        if failed_categories:
            print(f"  âŒ å¤±è´¥åˆ†ç±»: {', '.join(failed_categories)}")
        
        # æ£€æŸ¥æ±‡æ€»æŠ¥å‘Šæ˜¯å¦ç”Ÿæˆ
        if os.path.exists(output_dir):
            summary_files = [f for f in os.listdir(output_dir) if f.startswith('cumulative_summary_')]
            if summary_files:
                summary_file = sorted(summary_files)[-1]  # è·å–æœ€æ–°çš„æ±‡æ€»æŠ¥å‘Š
                print(f"  ğŸ“‹ æ±‡æ€»æŠ¥å‘Š: {summary_file}")
        
        print(f"\nğŸ‰ ç´¯ç§¯æ–°é—»æ›´æ–°å®Œæˆï¼è¯·æŸ¥çœ‹ç›®å½•: {os.path.abspath(output_dir)}")
        return True
        
    except Exception as e:
        print(f"âŒ å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

def show_help():
    """
    æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    """
    print("=" * 60)
    print("ğŸ“– ç´¯ç§¯æ–°é—»æ±‡æ€»ç”Ÿæˆå™¨")
    print("=" * 60)
    print()
    print("åŠŸèƒ½è¯´æ˜:")
    print("  - è·å–æ‰€æœ‰RSSè®¢é˜…æºçš„å†å²æ–°é—»ï¼ˆä¸é™æ—¶é—´èŒƒå›´ï¼‰")
    print("  - è‡ªåŠ¨å»é‡ï¼Œé¿å…é‡å¤æ·»åŠ ç›¸åŒæ–‡ç« ")
    print("  - å°†æ–°æ–‡ç« è¿½åŠ åˆ°ç´¯ç§¯çš„Markdownæ–‡æ¡£ä¸­")
    print("  - æŒ‰åˆ†ç±»ç”Ÿæˆç‹¬ç«‹çš„ç´¯ç§¯æ–‡æ¡£")
    print("  - é€‚åˆå®šæœŸæ‰§è¡Œï¼ŒæŒç»­æ›´æ–°æ–°é—»åº“")
    print()
    print("è¾“å‡ºæ–‡ä»¶:")
    print("  - cumulative_news/åˆ†ç±»å_cumulative.md")
    print("  - cumulative_news/cumulative_summary_YYYYMMDD_HHMM.md")
    print()
    print("å»é‡æœºåˆ¶:")
    print("  - åŸºäºæ–‡ç« æ ‡é¢˜å’Œé“¾æ¥ç”Ÿæˆå”¯ä¸€å“ˆå¸Œå€¼")
    print("  - è‡ªåŠ¨è·³è¿‡å·²å­˜åœ¨çš„æ–‡ç« ")
    print("  - æ–°æ–‡ç« è¿½åŠ åˆ°æ–‡æ¡£å¼€å¤´ï¼Œä¿æŒæ—¶é—´é¡ºåº")
    print()
    print("ä½¿ç”¨æ–¹æ³•:")
    print("  python ç”Ÿæˆç´¯ç§¯æ–°é—».py")
    print("  python ç”Ÿæˆç´¯ç§¯æ–°é—».py --help")
    print()
    print("å»ºè®®å®šæœŸæ‰§è¡Œï¼ˆå¦‚æ¯å¤©ä¸€æ¬¡ï¼‰ï¼Œä¿æŒæ–°é—»åº“çš„æ›´æ–°")

if __name__ == "__main__":
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1 and sys.argv[1] in ['--help', '-h', 'help']:
        show_help()
    else:
        # æ‰§è¡Œä¸»ç¨‹åº
        success = main()
        
        if success:
            print("\nğŸ¯ ä»»åŠ¡å®Œæˆï¼")
        else:
            print("\nğŸ’¥ ä»»åŠ¡å¤±è´¥ï¼")
            sys.exit(1)