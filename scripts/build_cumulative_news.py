"""
ç´¯ç§¯æ–°é—»ç”Ÿæˆè„šæœ¬

è·å–æ‰€æœ‰RSSè®¢é˜…æºçš„å†å²æ–°é—»ï¼Œè¿½åŠ åˆ°ç´¯ç§¯çš„Markdownæ–‡æ¡£ä¸­
"""

import sys
import os
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from news_agent.config_loader import load_config
from news_agent.rss.reader import generate_historical_news_by_categories


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç”Ÿæˆç´¯ç§¯æ–°é—»æ±‡æ€»')
    parser.add_argument('--max-articles', type=int, default=100, help='æ¯ä¸ªæºæœ€å¤šè·å–çš„æ–‡ç« æ•°')
    parser.add_argument('--max-reports', type=int, default=10, help='æœ€å¤šä¿ç•™çš„æ±‡æ€»æŠ¥å‘Šæ•°')
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ”„ ç´¯ç§¯æ–°é—»æ±‡æ€»ç”Ÿæˆå™¨")
    print("=" * 60)
    
    # åŠ è½½é…ç½®
    config = load_config()
    paths = config['paths']
    rss_sources = config['rss_sources']
    
    if not rss_sources:
        print("âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•RSSè®¢é˜…æºé…ç½®")
        return False
    
    output_dir = str(paths['cumulative_news'])
    
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"  - è¾“å‡ºç›®å½•: {output_dir}")
    print(f"  - RSSæºæ•°é‡: {len(rss_sources)}")
    print(f"  - æ¯æºæœ€å¤§æ–‡ç« æ•°: {args.max_articles}")
    print(f"  - æœ€å¤§æ±‡æ€»æŠ¥å‘Šæ•°: {args.max_reports}")
    
    # ç»Ÿè®¡åˆ†ç±»
    categories = {}
    for source in rss_sources:
        category = source.get('category', 'æœªåˆ†ç±»')
        categories[category] = categories.get(category, 0) + 1
    
    print(f"\nğŸ“‚ å‘ç° {len(categories)} ä¸ªåˆ†ç±»:")
    for category, count in categories.items():
        print(f"  - {category}: {count} ä¸ªè®¢é˜…æº")
    
    print("\n" + "-" * 60)
    
    # ç”Ÿæˆç´¯ç§¯æ–°é—»
    print("ğŸ”„ å¼€å§‹è·å–å†å²æ–°é—»å¹¶æ›´æ–°ç´¯ç§¯æ–‡æ¡£...")
    results = generate_historical_news_by_categories(
        rss_sources=rss_sources,
        output_dir=output_dir,
        max_articles_per_source=args.max_articles,
        max_summary_reports=args.max_reports
    )
    
    if not results:
        print("âŒ å¤„ç†å¤±è´¥")
        return False
    
    # è¾“å‡ºç»“æœç»Ÿè®¡
    print("\n" + "=" * 60)
    print("ğŸ“Š å¤„ç†ç»“æœç»Ÿè®¡:")
    print("=" * 60)
    
    successful_categories = []
    failed_categories = []
    total_new_articles = 0
    total_duplicate_articles = 0
    
    for category, result in results.items():
        if result.get('success', False):
            successful_categories.append(category)
            new_count = result.get('new_count', 0)
            duplicate_count = result.get('duplicate_count', 0)
            total_new_articles += new_count
            total_duplicate_articles += duplicate_count
            
            print(f"âœ… {category}:")
            print(f"   ğŸ“„ æ–‡ä»¶: {os.path.basename(result['file_path'])}")
            print(f"   ğŸ†• æ–°å¢æ–‡ç« : {new_count}")
            print(f"   ğŸ”„ é‡å¤æ–‡ç« : {duplicate_count}")
            print(f"   ğŸ”— è®¢é˜…æºæ•°: {result.get('source_count', 0)}")
        else:
            failed_categories.append(category)
            error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
            print(f"âŒ {category}: {error_msg}")
    
    print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
    print(f"  âœ… æˆåŠŸå¤„ç†: {len(successful_categories)}/{len(results)} ä¸ªåˆ†ç±»")
    print(f"  ğŸ†• æ–°å¢æ–‡ç« æ€»æ•°: {total_new_articles}")
    print(f"  ğŸ”„ é‡å¤æ–‡ç« æ€»æ•°: {total_duplicate_articles}")
    print(f"  ğŸ“ è¾“å‡ºç›®å½•: {os.path.abspath(output_dir)}")
    
    if failed_categories:
        print(f"  âŒ å¤±è´¥åˆ†ç±»: {', '.join(failed_categories)}")
    
    print(f"\nğŸ‰ ç´¯ç§¯æ–°é—»æ›´æ–°å®Œæˆï¼")
    return True


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
