"""
RSS Feed ç”Ÿæˆå™¨

è¯¥è„šæœ¬è¯»å–å½“å¤©å„åˆ†ç±»çš„æ–°é—»Markdownæ–‡ä»¶ï¼Œä¸ºæ¯ä¸ªåˆ†ç±»ç”Ÿæˆå¯¹åº”çš„RSS XMLæ–‡ä»¶ï¼Œ
ä¿å­˜åˆ°"feed"æ–‡ä»¶å¤¹ä¸­ï¼Œå¯ä½œä¸ºRSSè®¢é˜…æºä½¿ç”¨ã€‚
"""

import os
import sys
import re
from datetime import datetime
from xml.etree.ElementTree import Element, SubElement, tostring
from xml.dom import minidom
from urllib.parse import quote

def parse_markdown_news(md_file_path):
    """
    è§£æMarkdownæ–°é—»æ–‡ä»¶ï¼Œæå–æ–‡ç« ä¿¡æ¯
    
    å‚æ•°:
        md_file_path (str): Markdownæ–‡ä»¶è·¯å¾„
        
    è¿”å›:
        dict: åŒ…å«æ–°é—»ä¿¡æ¯çš„å­—å…¸
    """
    try:
        with open(md_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶ {md_file_path}: {e}")
        return None
    
    # æå–åŸºæœ¬ä¿¡æ¯
    info = {
        'title': '',
        'description': '',
        'pub_date': '',
        'articles': []
    }
    
    # æå–æ ‡é¢˜
    title_match = re.search(r'^# (.+)', content, re.MULTILINE)
    if title_match:
        info['title'] = title_match.group(1).strip()
    
    # æå–ç”Ÿæˆæ—¶é—´
    time_match = re.search(r'\*\*ç”Ÿæˆæ—¶é—´\*\*:\s*(.+)', content)
    if time_match:
        time_str = time_match.group(1).strip()
        try:
            # å°è¯•è§£ææ—¶é—´æ ¼å¼
            pub_date = datetime.strptime(time_str, '%Y-%m-%d %H:%M')
            info['pub_date'] = pub_date.strftime('%a, %d %b %Y %H:%M:%S GMT')
        except ValueError:
            info['pub_date'] = datetime.now().strftime('%a, %d %b %Y %H:%M:%S GMT')
    else:
        info['pub_date'] = datetime.now().strftime('%a, %d %b %Y %H:%M:%S GMT')
    
    # æå–æ–‡ç« æ€»æ•°ä½œä¸ºæè¿°
    count_match = re.search(r'\*\*æ–‡ç« æ€»æ•°\*\*:\s*(\d+)', content)
    if count_match:
        article_count = count_match.group(1)
        info['description'] = f"æœ€æ–°ç§‘æŠ€èµ„è®¯æ±‡æ€»ï¼ŒåŒ…å« {article_count} ç¯‡æ–‡ç« "
    else:
        info['description'] = "æœ€æ–°ç§‘æŠ€èµ„è®¯æ±‡æ€»"
    
    # æå–æ‰€æœ‰æ–‡ç« 
    # åŒ¹é…æ ¼å¼: ### [æ ‡é¢˜](é“¾æ¥)
    article_pattern = r'### \[(.+?)\]\((.+?)\)\s*(?:\*\*å‘å¸ƒæ—¶é—´\*\*:\s*(.+?)(?:\n|$))?'
    articles = re.findall(article_pattern, content, re.MULTILINE | re.DOTALL)
    
    for title, link, pub_time in articles:
        # æ¸…ç†æ ‡é¢˜ä¸­çš„è½¬ä¹‰å­—ç¬¦
        clean_title = title.replace('\\[', '[').replace('\\]', ']').strip()
        clean_link = link.strip()
        clean_pub_time = pub_time.strip() if pub_time else ''
        
        # è½¬æ¢å‘å¸ƒæ—¶é—´æ ¼å¼
        rss_pub_time = ''
        if clean_pub_time:
            try:
                # å°è¯•å¤šç§æ—¶é—´æ ¼å¼
                for fmt in ['%Y-%m-%d %H:%M', '%a, %d %b %Y %H:%M:%S %z', '%Y-%m-%d %H:%M:%S']:
                    try:
                        dt = datetime.strptime(clean_pub_time, fmt)
                        rss_pub_time = dt.strftime('%a, %d %b %Y %H:%M:%S GMT')
                        break
                    except ValueError:
                        continue
            except:
                pass
        
        if not rss_pub_time:
            rss_pub_time = info['pub_date']
        
        info['articles'].append({
            'title': clean_title,
            'link': clean_link,
            'pub_date': rss_pub_time,
            'description': clean_title  # ä½¿ç”¨æ ‡é¢˜ä½œä¸ºæè¿°
        })
    
    return info

def generate_rss_xml(news_info, category, base_url="https://your-domain.com"):
    """
    ç”ŸæˆRSS XMLå†…å®¹
    
    å‚æ•°:
        news_info (dict): æ–°é—»ä¿¡æ¯
        category (str): åˆ†ç±»åç§°
        base_url (str): ç½‘ç«™åŸºç¡€URL
        
    è¿”å›:
        str: RSS XMLå­—ç¬¦ä¸²
    """
    # åˆ›å»ºRSSæ ¹å…ƒç´ 
    rss = Element('rss')
    rss.set('version', '2.0')
    rss.set('xmlns:atom', 'http://www.w3.org/2005/Atom')
    
    # åˆ›å»ºchannelå…ƒç´ 
    channel = SubElement(rss, 'channel')
    
    # æ·»åŠ é¢‘é“ä¿¡æ¯
    title = SubElement(channel, 'title')
    title.text = f"{category} æ–°é—»æ±‡æ€» - Free News Agent"
    
    link = SubElement(channel, 'link')
    link.text = f"{base_url}/feed/{category.lower()}freenewsagent.xml"
    
    description = SubElement(channel, 'description')
    description.text = f"{category} åˆ†ç±»çš„æœ€æ–°æ–°é—»æ±‡æ€»ï¼Œç”± Free News Agent è‡ªåŠ¨ç”Ÿæˆ"
    
    language = SubElement(channel, 'language')
    language.text = "zh-CN"
    
    pub_date = SubElement(channel, 'pubDate')
    pub_date.text = news_info.get('pub_date', datetime.now().strftime('%a, %d %b %Y %H:%M:%S GMT'))
    
    last_build_date = SubElement(channel, 'lastBuildDate')
    last_build_date.text = datetime.now().strftime('%a, %d %b %Y %H:%M:%S GMT')
    
    generator = SubElement(channel, 'generator')
    generator.text = "News Agent RSS Generator"
    
    # æ·»åŠ æ‰€æœ‰æƒè®¤è¯æ ‡ç­¾
    follow_challenge = SubElement(channel, 'follow_challenge')
    feed_id = SubElement(follow_challenge, 'feedId')
    feed_id.text = "150741279739242496"
    user_id = SubElement(follow_challenge, 'userId')
    user_id.text = "DdasOQb1gouc5RwqkaQc4KLscHJhfeeW"
    
    # æ·»åŠ atom:linkè‡ªå¼•ç”¨
    atom_link = SubElement(channel, 'atom:link')
    atom_link.set('href', f"{base_url}/feed/{category.lower()}freenewsagent.xml")
    atom_link.set('rel', 'self')
    atom_link.set('type', 'application/rss+xml')
    
    # æ·»åŠ æ–‡ç« é¡¹ç›®
    for article in news_info.get('articles', []):
        item = SubElement(channel, 'item')
        
        item_title = SubElement(item, 'title')
        item_title.text = article['title']
        
        item_link = SubElement(item, 'link')
        item_link.text = article['link']
        
        item_description = SubElement(item, 'description')
        item_description.text = f"<![CDATA[{article['description']}]]>"
        
        item_pub_date = SubElement(item, 'pubDate')
        item_pub_date.text = article['pub_date']
        
        # æ·»åŠ GUID
        guid = SubElement(item, 'guid')
        guid.set('isPermaLink', 'true')
        guid.text = article['link']
        
        # æ·»åŠ åˆ†ç±»
        item_category = SubElement(item, 'category')
        item_category.text = category
    
    # æ ¼å¼åŒ–XML
    rough_string = tostring(rss, 'utf-8')
    reparsed = minidom.parseString(rough_string)
    return reparsed.toprettyxml(indent="  ", encoding='utf-8').decode('utf-8')

def get_today_news_files(news_dir="news"):
    """
    è·å–ä»Šå¤©çš„æ–°é—»æ–‡ä»¶åˆ—è¡¨
    
    å‚æ•°:
        news_dir (str): æ–°é—»ç›®å½•
        
    è¿”å›:
        list: æ–°é—»æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    today = datetime.now().strftime('%Y%m%d')
    today_dir = os.path.join(news_dir, today)
    
    if not os.path.exists(today_dir):
        print(f"âŒ ä»Šæ—¥æ–°é—»ç›®å½•ä¸å­˜åœ¨: {today_dir}")
        return []
    
    news_files = []
    for filename in os.listdir(today_dir):
        if filename.endswith('.md') and not filename.startswith('summary_'):
            news_files.append(os.path.join(today_dir, filename))
    
    return news_files

def extract_category_from_filename(filename):
    """
    ä»æ–‡ä»¶åä¸­æå–åˆ†ç±»åç§°
    
    å‚æ•°:
        filename (str): æ–‡ä»¶å
        
    è¿”å›:
        str: åˆ†ç±»åç§°
    """
    # æ–‡ä»¶åæ ¼å¼: åˆ†ç±»å_æ—¥æœŸ.md
    basename = os.path.basename(filename)
    name_part = basename.split('_')[0] if '_' in basename else basename.replace('.md', '')
    return name_part

def main():
    """
    ä¸»å‡½æ•°ï¼šç”ŸæˆRSS Feed XMLæ–‡ä»¶
    """
    print("=" * 60)
    print("ğŸ”„ RSS Feed ç”Ÿæˆå™¨")
    print("=" * 60)
    
    # é…ç½®å‚æ•°
    news_dir = "news"
    feed_dir = "feed"
    base_url = "https://zskfree.github.io/News-Agent"  # å¯ä»¥ä¿®æ”¹ä¸ºæ‚¨çš„åŸŸå
    
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"  - æ–°é—»ç›®å½•: {news_dir}")
    print(f"  - Feedè¾“å‡ºç›®å½•: {feed_dir}")
    print(f"  - åŸºç¡€URL: {base_url}")
    print()
    
    # åˆ›å»ºfeedç›®å½•
    if not os.path.exists(feed_dir):
        os.makedirs(feed_dir)
        print(f"âœ… åˆ›å»ºFeedç›®å½•: {feed_dir}")
    
    # è·å–ä»Šå¤©çš„æ–°é—»æ–‡ä»¶
    news_files = get_today_news_files(news_dir)
    
    if not news_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»Šå¤©çš„æ–°é—»æ–‡ä»¶")
        return False
    
    print(f"ğŸ“° æ‰¾åˆ° {len(news_files)} ä¸ªæ–°é—»æ–‡ä»¶")
    print("-" * 60)
    
    success_count = 0
    failed_count = 0
    
    # ä¸ºæ¯ä¸ªåˆ†ç±»ç”ŸæˆRSS Feed
    for news_file in news_files:
        category = extract_category_from_filename(news_file)
        print(f"ğŸ”„ å¤„ç†åˆ†ç±»: {category}")
        
        try:
            # è§£æMarkdownæ–‡ä»¶
            news_info = parse_markdown_news(news_file)
            
            if not news_info:
                print(f"  âŒ è§£æå¤±è´¥")
                failed_count += 1
                continue
            
            article_count = len(news_info.get('articles', []))
            print(f"  ğŸ“„ è§£æåˆ° {article_count} ç¯‡æ–‡ç« ")
            
            # ç”ŸæˆRSS XML
            rss_xml = generate_rss_xml(news_info, category, base_url)
            
            # ä¿å­˜XMLæ–‡ä»¶
            xml_filename = f"{category.lower()}freenewsagent.xml"
            xml_path = os.path.join(feed_dir, xml_filename)
            
            with open(xml_path, 'w', encoding='utf-8') as f:
                f.write(rss_xml)
            
            print(f"  âœ… ç”ŸæˆæˆåŠŸ: {xml_filename}")
            success_count += 1
            
        except Exception as e:
            print(f"  âŒ ç”Ÿæˆå¤±è´¥: {e}")
            failed_count += 1
    
    # è¾“å‡ºç»Ÿè®¡ç»“æœ
    print("\n" + "=" * 60)
    print("ğŸ“Š ç”Ÿæˆç»“æœç»Ÿè®¡:")
    print("=" * 60)
    print(f"  âœ… æˆåŠŸç”Ÿæˆ: {success_count} ä¸ªRSS Feed")
    print(f"  âŒ ç”Ÿæˆå¤±è´¥: {failed_count} ä¸ª")
    print(f"  ğŸ“ è¾“å‡ºç›®å½•: {os.path.abspath(feed_dir)}")
    
    if success_count > 0:
        print(f"\nğŸ“¡ RSSè®¢é˜…åœ°å€:")
        for news_file in news_files:
            category = extract_category_from_filename(news_file)
            xml_filename = f"{category.lower()}.xml"
            if os.path.exists(os.path.join(feed_dir, xml_filename)):
                print(f"  - {category}: {base_url}/feed/{xml_filename}")
    
    print(f"\nğŸ‰ RSS Feedç”Ÿæˆå®Œæˆï¼")
    return success_count > 0

def show_help():
    """
    æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
    """
    print("=" * 60)
    print("ğŸ“– RSS Feed ç”Ÿæˆå™¨")
    print("=" * 60)
    print()
    print("åŠŸèƒ½è¯´æ˜:")
    print("  - è¯»å–å½“å¤©å„åˆ†ç±»çš„æ–°é—»Markdownæ–‡ä»¶")
    print("  - ä¸ºæ¯ä¸ªåˆ†ç±»ç”Ÿæˆå¯¹åº”çš„RSS XMLæ–‡ä»¶")
    print("  - ä¿å­˜åˆ°feedæ–‡ä»¶å¤¹ä¸­ï¼Œå¯ä½œä¸ºRSSè®¢é˜…æº")
    print("  - æ”¯æŒæ ‡å‡†RSS 2.0æ ¼å¼")
    print()
    print("è¾“å…¥æ–‡ä»¶:")
    print("  - news/YYYYMMDD/åˆ†ç±»å_YYYYMMDD.md")
    print()
    print("è¾“å‡ºæ–‡ä»¶:")
    print("  - feed/åˆ†ç±»å.xml")
    print()
    print("ä½¿ç”¨æ–¹æ³•:")
    print("  python ç”ŸæˆRSS_Feed.py")
    print("  python ç”ŸæˆRSS_Feed.py --help")
    print()
    print("æ³¨æ„äº‹é¡¹:")
    print("  - éœ€è¦å…ˆè¿è¡Œæ–°é—»æ±‡æ€»ç”Ÿæˆå™¨ç”Ÿæˆå½“å¤©çš„æ–°é—»æ–‡ä»¶")
    print("  - å¯ä»¥ä¿®æ”¹è„šæœ¬ä¸­çš„base_urlä¸ºæ‚¨çš„å®é™…åŸŸå")

if __name__ == "__main__":
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1 and sys.argv[1] in ['--help', '-h', 'help']:
        show_help()
    else:
        # æ‰§è¡Œä¸»ç¨‹åº
        success = main()
        
        if success:
            print("\nğŸ¯ ä»»åŠ¡å®Œæˆï¼")
        else:
            print("\nğŸ’¥ ä»»åŠ¡å¤±è´¥ï¼")
            sys.exit(1)
